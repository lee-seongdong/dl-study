{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(seed=1234, device=device(type='cuda'))\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "args = {\n",
    "    \"seed\": 1234,\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "}\n",
    "\n",
    "args = argparse.Namespace(**args)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[PAD]': 0, '[UNK]': 1, '나는': 2, '학생': 3, '입니다': 4, '좋은': 5, '선생님': 6, '당신은': 7, '매우': 8}\n",
      "{0: '[PAD]', 1: '[UNK]', 2: '나는', 3: '학생', 4: '입니다', 5: '좋은', 6: '선생님', 7: '당신은', 8: '매우'}\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = [\n",
    "    \"나는 학생 입니다\",\n",
    "    \"나는 좋은 선생님 입니다\",\n",
    "    \"당신은 매우 좋은 선생님 입니다\"\n",
    "]\n",
    "\n",
    "# 학생 : 1, 기타 : 0\n",
    "raw_labels = [1, 0, 0]\n",
    "\n",
    "words = []\n",
    "for s in raw_inputs:\n",
    "    words.extend(s.split())\n",
    "\n",
    "words = list(dict.fromkeys(words))\n",
    "word_to_id = {\"[PAD]\": 0, \"[UNK]\": 1}\n",
    "for w in words:\n",
    "    word_to_id[w] = len(word_to_id)\n",
    "\n",
    "print(word_to_id)\n",
    "\n",
    "id_to_word = {i: w for w, i in word_to_id.items()}\n",
    "print(id_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "[[2 3 4 0 0]\n",
      " [2 5 6 4 0]\n",
      " [7 8 5 6 4]]\n",
      "[[[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0. 0.]]]\n",
      "[[2 3 4 0 0]\n",
      " [2 5 6 4 0]\n",
      " [7 8 5 6 4]]\n"
     ]
    }
   ],
   "source": [
    "onehot_metrix = np.eye(len(word_to_id))\n",
    "print(onehot_metrix)\n",
    "\n",
    "train_inputs = []\n",
    "for s in raw_inputs:\n",
    "    row = [word_to_id[w] for w in s.split()]\n",
    "    row += [0] * (5-len(row)) # PAD\n",
    "    train_inputs.append(row)\n",
    "train_inputs = np.array(train_inputs)\n",
    "\n",
    "print(train_inputs)\n",
    "\n",
    "train_onehot = onehot_metrix[train_inputs]\n",
    "print(train_onehot)\n",
    "\n",
    "a = np.argmax(train_onehot, axis=-1)\n",
    "print(np.argmax(train_onehot, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2153,  0.8840, -0.7584, -0.3689],\n",
      "         [-0.3424, -1.4020,  0.3206, -1.0219],\n",
      "         [ 0.7988, -0.0923, -0.7049, -1.6024],\n",
      "         [-0.1117, -0.4966,  0.1631, -0.8817],\n",
      "         [-0.1117, -0.4966,  0.1631, -0.8817]],\n",
      "\n",
      "        [[-0.2153,  0.8840, -0.7584, -0.3689],\n",
      "         [-0.5675, -0.2772, -2.1834,  0.3668],\n",
      "         [ 0.7667,  0.0190,  0.0220,  1.1532],\n",
      "         [ 0.7988, -0.0923, -0.7049, -1.6024],\n",
      "         [-0.1117, -0.4966,  0.1631, -0.8817]],\n",
      "\n",
      "        [[ 1.8409, -1.0174,  1.2192,  0.1601],\n",
      "         [-0.6857, -0.0496, -1.2485, -0.8509],\n",
      "         [-0.5675, -0.2772, -2.1834,  0.3668],\n",
      "         [ 0.7667,  0.0190,  0.0220,  1.1532],\n",
      "         [ 0.7988, -0.0923, -0.7049, -1.6024]]], grad_fn=<EmbeddingBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[-0.1117, -0.4966,  0.1631, -0.8817],\n",
      "        [ 0.0539,  0.6684, -0.0597, -0.4675],\n",
      "        [-0.2153,  0.8840, -0.7584, -0.3689],\n",
      "        [-0.3424, -1.4020,  0.3206, -1.0219],\n",
      "        [ 0.7988, -0.0923, -0.7049, -1.6024],\n",
      "        [-0.5675, -0.2772, -2.1834,  0.3668],\n",
      "        [ 0.7667,  0.0190,  0.0220,  1.1532],\n",
      "        [ 1.8409, -1.0174,  1.2192,  0.1601],\n",
      "        [-0.6857, -0.0496, -1.2485, -0.8509]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "t_train_inputs = torch.tensor(train_inputs)\n",
    "t_train_onehots = torch.tensor(train_onehot).to(torch.float32)\n",
    "\n",
    "embed = torch.nn.Embedding(len(word_to_id), 4)\n",
    "\n",
    "hidden1 = embed(t_train_inputs)\n",
    "print(hidden1)\n",
    "\n",
    "print(embed.weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-study-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
